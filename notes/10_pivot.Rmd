---
title: "10. Restructuring Data"
author: ""
output:
  html_document:
    theme: cosmo
    highlight: zenburn
    css: "note-style.css"
---

```{r, include=FALSE}
library(tidyverse)
library(ggrepel)
library(stringi)
library(smodels)

theme_set(theme_minimal())
options(pillar.min_character_chars = 15)

food <- read_csv(file.path("data", "food.csv"))
food_prices <- read_csv(file.path("data", "food_prices.csv"))
```

## Motivation

In this chapter we introduce another set of methods for manipulating datasets.
Table pivots, which are related by not identical to the spreadsheet concept of
a *pivot table*, are a way or rearranging the values in a table without adding
or lossing any additional information. This is achieved by either making the table
longer (more rows, fewer columns) or wider (more columns, fewer rows).

What sort of situations would require going between two different formats with
a different number of rows? As an example, consider a hypothetical experiment
where we measure the heights of 100 plants every morning for two weeks. There are
two different ways to store this data. We could have 100 rows, one for each plant,
with variables `height_day1`, `height_day2`, and so on all the way through
`height_day14`. Alternatively, we could have 1400 rows with just three columns:
an id for the plant, a variable for the day, and a variable for height. Notice
that both of these options capture the same information, but each privleges a
particular kind of analysis.

In the wider table format, it is straightforward to compute the amount that each
plot grew over the two weeks using a single mutate function. In the longer table
format, it would be straightforward to filter by a specific plant id and draw a
line plot showing the growth of a specific plant over the two week period. Both
drawing a plot with the wider table or computing the growth with the longer table
are possible, but require a surprising amount of work and code.

In this chapter we will introduce two new functions for alternating between wider
and longer formats for a dataset. These are principles that will be fundamental to
several of the application chapters, particularly with text and temporal datasets.

## Pivot wider

For this chapter, we will make use of the `food_prices` dataset. As shown in our
motivation example, pivoting is often a useful operation to apply when analyzing
data collected over time. The dataset is organized with year as the observation
and each food type as a column.

```{r}
food_prices
```

This format makes it straightforward to compute the correlation between the
prices of different kinds of food items. A longer format for the dataset would,
instead, have one row for each combination of year and food time.

In order to make this table longer, we will apply the `pivot_longer` function.
This function requires knowing which current variables in the dataset should
be turned into values in the output dataset. Often, it is easier to describe
the set of values that will *not* be turned into values. Here, we indicate
(with a minus sign) that the year value should remain as a variable in the output
dataset:

```{r}
food_prices %>%
  pivot_longer(-c(year))
```

Already this looks close to what a long form of the food prices dataset should look
like. One improvement that we can make is to set better column names, which can be
done by setting the options `names_to` and `values_to` in the function call:

```{r}
food_prices %>%
  pivot_longer(-c(year), names_to = "food", values_to = "price")
```

The longer form of the dataset makes it much easier to do some kinds of analysis.
For example, we can draw a line chart of all of the food prices with a single
graphics layer:

```{r}
food_prices %>%
  pivot_longer(-year, names_to = "food", values_to = "price") %>%
  ggplot() +
    geom_line(aes(x = year, y = price, color = food))
```

Drawing this plot with the original dataset would require manually including a layer
for each food type, selecting their colors, and building a manual legend. The alternative
using the longer table is certainly the preferred approach.

## Pivot wider

To illustrate making a table wider, let's create a new dataset consisting of the long
format of the food prices dataset from just the years 1950 and 1975:

```{r}
food_prices_long <- food_prices %>%
  pivot_longer(-year, names_to = "food", values_to = "price") %>%
  filter(year %in% c(1950, 1975))
```

As described in our motivating example, it makes sense for some analyses to make
each time point a column in a wider dataset. To do this, we use the `pivot_wider`
function. We need to indicate the current variable contains the values that will
become new columns and the variable from which to take the values for the new
column from. Here, the names will come from the `years` column (we want a new
column for 1950 and another one for 1975) and the values will be filled in with
prices.

```{r}
food_prices_long %>%
  pivot_wider(names_from = year, values_from = price)
```

One problem with the default output is that the column names now start with a number,
which is not an allowed variable name in R. This makes it awkward to work with the
dataset; it is better to add a prefix to the names to make them valid. This can be
done by setting the `names_prefix` option in the `pivot_wider` function.

```{r}
food_prices_long %>%
  pivot_wider(
    names_from = year, values_from = price, names_prefix = "year_"
  )
```

This new form of the dataset makes it straightforward to plot the price of each food
type in 1975 as a function of its price in 1950.

```{r}
food_prices_long %>%
  pivot_wider(names_from = year, values_from = price, names_prefix = "year_") %>%
  ggplot() +
    geom_point(aes(x = year_1950, y = year_1975)) +
    geom_text_repel(aes(x = year_1950, y = year_1975, label = food))
```

We can add some of the polishing touches mentioned in Chapter 8 to make the plot even
more readable.

```{r}
food_prices_long %>%
  pivot_wider(names_from = year, values_from = price, names_prefix = "year_") %>%
  mutate(food = stri_trans_totitle(food)) %>%
  ggplot() +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
    geom_point(aes(x = year_1950, y = year_1975)) +
    geom_text_repel(aes(x = year_1950, y = year_1975, label = food)) +
    labs(x = "Price Index (1950)", y = "Price Index (1975)") +
    theme_sm()
```

In this new plot, can you see what products got much more expensive, much less expensive, and
stayed about the same from 1950 to 1975?

## Patterns for table pivots

The syntax for making tables wider or longer is, on the surface, not much more complex than
other table verbs that we have covered in this text. The biggest challenges with table pivots
are identifying when they will simplify an analysis and not over-using them. The best
way to avoid these issues is to store your data in the longest format that makes sense for
your data. For example, in the motivating example about plant growth, it is better to store
the data with 1400 rows and 3 columns.

Storing data in a longer format has a number of benefits. Reducing the number of columns
makes it easier to document the (smaller set of) variables with a well-written data dictionary.
Also, while avoided in our simple examples within this chapter, pivoting wider also often
requires less code and results in fewer bugs. Several of these are illustrated in the
chapter's exercises.

Perhaps the biggest benefit of storing data in a longer format is to avoid the potentially
complex chain of operations required to make the plot at the end of the previous section.
The original dataset is stored with years as rows and items as columns. Producing the plot
requires thinking of years and columns and items as rows; this needed us to first pivot
longer and then pivot wider. Keeping data in a longer format avoids the need for double
pivots, while also making the different kinds of analysis (item and year, year by item,
item by year) all reasonable accessible.

In my experience, some social scientists have a bad habit of storing data in extremely
wide and unwieldly formats. It seems to be something that comes from the way that feels
natural to organize survey and time-series datasets. For example, the U.S. Census Bureau
produces datasets that often have hundreds of columns. Keep this in mind as you collect
your own data, or work with external sources. Often an analysis that looks difficult at
first will appear quite straightforward after pivoting your dataset to a longer format.

## Exercises and References

There is are exercise notebook for this chapter:

- **exercies10A.Rmd**: practice applying table pivots to a new dataset
- **exercies10B.Rmd**: practice applying table pivots to structure a wide dataset  
- **exercies10C.Rmd**: open-ended questions of a time-series dataset using pivots

It is strongly recommended to complete at least the first notebook prior to
continuing on to the next chapter.

Here are several good resources if you want to learn more about data pivots in R:

- [pivot_wider documentation](https://tidyr.tidyverse.org/reference/pivot_wider.html)
- [pivot_longer documentation](https://tidyr.tidyverse.org/reference/pivot_longer.html)
- [Tidy Data code-based article](https://tidyr.tidyverse.org/articles/tidy-data.html)
