---
title: "Notebook 10A"
output: html_document
---

```{r, include=FALSE}
library(tidyverse)
library(ggrepel)
library(smodels)
library(stringi)

theme_set(theme_minimal())
options(pillar.min_character_chars = 15)
```

## Instructions

This notebook includes several tasks to practice and extend your knowledge of
the material covered within the chapter. For the most part, every notebook with
a name ended in "A" will work with a collection of data about cities and their
population. The questions tend to be relatively contained; the focus is
primarily on writing code to perform a specific task. For this purpose there
will usually be an empty code block for you to put your code. There are also
questions requiring a short response, prompted by the phrase "**Answer:**".
Your answers to these can be write directly in this notebook. Occasionally
new functions or concepts will be shown within each notebook.

Notebooks ending in letters other than "A" more often include new datasets and
open-ended prompts for using the data skills covered in the chapters to address
a wide range of questions. It is suggested to start with the "A" notebook for
each chapter and then trying to work through at least one additional data
project notebook.

When you are done with your code, hitting the *knit* button in the toolbar will
produce an HTML webpage with all of your results. Note that the first time you
run the knit function may require installing some packages. Knitting your code
is a good way to help check that you have written all of the code correctly and
have not accidentally modified anything as you worked through the notebook.

Two important pieces of advice when working through the notebooks:

- It is a best practice to close RStudio everytime that you finish with a
notebook and before you start working on another dataset. This starts each
notebook from scratch and does not risk accidentally using variables created in
one notebook within the scope of another.

- Notice that the notebook file does not automatically word-wrap the way you
may be used to in a word processor. Generally, you should manually hit enter to
start typing on a new line. I try to make sure that both my text and my code are
not very wide. Make sure to do the same with your code and responses. Also, make
sure that your notebook window is wide enough so that my text does not forceable
try to wrap. This is very hard to read and makes it much easier to work through
the notebook.

## Load Datasets

In this notebook we will work with the U.S. city population dataset.

```{r, message=FALSE}
us <- read_csv(file.path("..", "data", "us_city_population.csv"))
```

Please refer to notebook02a for more information about the dataset.

## Widening Data: Cities as Observations

The `us` cities dataset is a perfect candidate for widening. In its default
form, there is one row for each unique combination of year and city. However,
some plots and analyses are easier if we create a dataset with either time or
the cities.

Let's start by creating a widened dataset where each row is a city. The
years will then be turned into columns. In the code below, create this
dataset using the `pivot_wider` function. As we saw in the chapter, use
the names prefix "year_" to avoid column names staring with a number.

```{r}

```

Below, take the dataset created in the previous block and filter to include only
cities with a population above 600 thousand in 2010. (Note: Do this after the pivot.
It is much easier that way.) Then, plot the population of each city in 1950 on
the x-axis and the population in 2010 on the y-axis with points and a text repel
layer using the city names. Use logarithmic scales for the x- and y-axes.

```{r}

```

Another graph that we can create using the wide version of the dataset is an arrow
plot showing the trend of each city over time. Below, piping the same data in as
above, create a plot using the `geom_segment` layer with city of the y-axis and
population on the x-axis. However, for this layer, you need to describe two
additional aesthetics: `xend` and `yend`. Set `x` to the population in 1950 and
`xend` to the population in 2010. The value for `yend` should be equal to the city
name, the same as `y`.

```{r}

```

One issue with this plot is that it does not show which direction the population
is changing (is it increasing or decreasing between 1950 and 2010?). We can fix
this by adding an option to the `geom_segement` layer that turns the segment into
a layer. Namely:

   `arrow = arrow(length = unit(0.02, "npc"))`

Below, modify the previous plot to include an arrow. Note that this line goes inside
the `geom_segement` function, after the `aes` command. You may need to indent into a
new line as is sometimes done in the notes to make the code easily readable. The
`0.02` effects the size of the arrow and can be modified as you see fit.

```{r}

```

As one last step, let's add some color to the plot. Below, modify the code
from the previous chunk to include a mutate verb that sets a variable
called `color` to "#FF7F7F" if the population decreased between 1950 and
2010 and to "#ADD8E6" if the population increased. You should be able to
do this with a single call to `if_else`. Then, color the lines with this
color using `scale_color_identify`. Also, make the line size `1.5` to make
the colors stand out more. Finally, order the cities by their size in 1950.


```{r}

```

## Widening Data: Years as Observations

Another possibility for pivoting the `us` dataset is to let the observations
by years and the variables be the city populations. In the code block below,
try to `pivot_wider` using names from the city variable and values from the
population. We do not need a variable prefix here.

```{r}

```

You should see that there is a problem. The issue is that there are several
other variables tied to each specific city (lon, lat, and state) that make
the output dataset have many missing values and far too many rows. Modify
the code above by first using the `select` function to grab only the three
variables `city`, `year`, and `population`.

```{r}

```

You should now have a dataset with 23 rows (one for each year) and 301
columns (a year column and 300 cities). The shape of this dataset is
fine, but the column names are difficult to work with because they contain
spaces and commas. We can fix this by changing the city names using some
string processing. I have started the code for you below. Add in the
select function and `pivot_wider` command to verify that it works as
expected:

```{r}
us %>%
  mutate(city = stri_trans_tolower(city)) %>%
  mutate(city = stri_replace_all(city, "", regex = "[^a-z ]")) %>%
  mutate(city = stri_replace_all(city, "_", fixed = " "))
```

Using this new dataset, create a plot with one city (of your choosing) on
the x-axis, another city (of your choosing) on the y-axis using a text layer
where the label is given by the year. This should allow you to see how the
population of the two cities change together over time.

```{r}

```

## Closing Thoughts

The `us` dataset is a nice example of how keeping data in a long format makes it
relatively easy to work with the data as-is or in various wider formats. In this
example, the cities as observations seems to allow more interesting plots. However,
the second format will be more useful for building the kinds of time series models
we introduce in the applications with temporal datasets.
