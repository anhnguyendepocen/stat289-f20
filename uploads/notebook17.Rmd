---
title: "Notebook 17"
output: html_document
---

## Getting Started

Before running this notebook, select "Session > Restart R and Clear Output" in
the menu above to start a new R session. This will clear any old data sets and
give us a blank slate to start with.

After starting a new session, run the following code chunk to load the
libraries and data that we will be working with today.

```{r, include=FALSE, message=FALSE}
library(tidyverse)
library(ggrepel)
library(smodels)
library(stringi)
library(lubridate)
library(sf)
library(units)
library(RcppRoll)
library(hms)

theme_set(theme_minimal())
options(dplyr.summarise.inform = FALSE)
options(width = 77L)
options(lubridate.week.start = 1)
Sys.setlocale(locale = "en_US.UTF-8")

sm_centroid <- function(data) {
  suppressWarnings({ z <- st_coordinates(st_centroid(data)) })
  return(tibble(lon = z[,1], lat = z[,2]))
}
spatial_join <- function(...) {
  return(st_as_sf(as_tibble(st_join(...))))
}
```

## Chicago Data

This notebook is intended to get you started thinking about how to work with
the various Chicago Datasets. It, and in particular my posted solutions, should
be helpful in your analysis.

### Load the Data

Let's load the data that we will be looking at through the remainder of the
semester:

```{r, message = FALSE}
comarea <- read_sf(file.path("data", "chicago_community_areas.geojson"))
ziparea <- read_sf(file.path("data", "zip_codes.geojson"))
socio <- read_csv(file.path("data", "census_socioeconomic.csv"))
medical <- read_csv(file.path("data", "chicago_medical_examiner_cases.csv.gz"))
crimes <- bind_rows(
  read_csv(file.path("data", "chicago_crimes_2001_2011.csv.gz")),
  read_csv(file.path("data", "chicago_crimes_2012_2020.csv.gz"))
)
schools <- read_sf(file.path("data", "chicago_schools.geojson"))
police <- read_sf(file.path("data", "chicago_police_stations.geojson"))
```

This time, we will look into the temporal components of the data
and see how they can be integrated into the spatial visualisations.

## Exploring the Corpus

### Univariate Exploration

Let's start with a few simple things to try to understand the data. Produce a
table showing the number of crimes associated with each `primary_type`. Sort
the data from most common to least common. Take a moment to look at the types.

```{r, question-01}

```

Repeat with the `description` variable. Notice that there are far more
categories here.

```{r, question-02}

```

And again with `location_desc`:

```{r, question-03}

```

### Spatial Analysis

Now, let's put a few variables together. Create a plot of the community areas
showing the number of crimes per person (perhaps per 1000 people). Note that
you should not try to directly merge the spatial data into the crimes. This is
too large and will crash R.

```{r, question-04}

```

Repeat the question above with crimes per household. Notice if there
are any large differences (in general, you can use either normalization,
depending on your preference).

```{r, question-05}

```

### Time

Let's see the overall pattern of crimes over time. Summarize the dataset to
show the number of crimes for each combination of year and month. Then, draw
a line plot with month on the x-axis, count on the y-axis, and add
`facet_wrap(~year)` to show the difference over year. Look at the plot and take
note of any filtering you might want to do before doing an future analysis.

```{r, question-06}

```

Now, show a line plot giving the number of crimes that occur by the hour of
the day. Do not separate by year. Notice any spikes in the data.

```{r, question-07}

```

Repeat the previous question, but count the data in buckets of 15 minutes.
What's going on in this plot? Do you see any outliers or strange patterns?

```{r, question-08}

```


### Multivariate Analysis

Show a scatter plot with one point for each community area, with the percentage
of households below the poverty line (`hh_poverty`) on the x-axis and the number
of crimes that occurred per person between 2003 and 2019 (inclusive) on the
y-axis.

```{r, message=FALSE, question-09}

```

Create a dataset showing the percentage of crimes that result in an arrest.
Note: It is best to do this using a call to `pivot_wider`.

```{r, question-10}

```

Starting with the data you created above, plot the percentage of crimes that
result in an arrest for each community area.

```{r, question-11}

```

Finally, show the percentage of crimes that result in an arrest that occur
during each hour of the day.

```{r, question-12}

```

### Multivariate by Area

Let's try to replicate the previous plot, but split the data into two groups.
One group will consist of data from "Rogers Park" (area 1); the other group
will come from the rest of the city. Your plot should now have two lines to
show the pattern for these two regions.

```{r, question-13}

```

And then repeat the same plot, but show the arrest rate pattern for these two
regions (Rogers Park vs. the rest of the city) by year.

```{r, question-14}

```

### Notes for Above

I tried to give a good idea of some of the things you can do and look at with
the Chicago dataset here. By changing the thing you are looking at the
percentage of (percent domestic, percent in a particular location, percent with
a particular description) you should be able to find several interesting
patterns. You can also filter the data further before looking at the split. For
example, only including one type of crime, or first filtering out a region of
interest and seeing how crimes changed from 2019 to 2020. We did not do this
above, but you can also see the seasonal differences in addition to time of day
and year-over-year.
